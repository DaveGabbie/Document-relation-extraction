{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c627be-b09c-4669-9225-96687d54798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,codecs,random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6edf9e-709d-4c74-ba6a-c8d9698e4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from recordtype import recordtype\n",
    "EntityInfo = recordtype('EntityInfo', 'type mstart mend sentNo')\n",
    "PairInfo = recordtype('PairInfo', 'type direction cross closeA closeB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4da9e69-fdb2-4381-b488-ec5e9155a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from l.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        assert len(l[i:i + n]) == n\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff4c271-1f2e-4286-b836-f4f62dff8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "entities = {}\n",
    "relations = {}\n",
    "num_entity = {}\n",
    "texts = []\n",
    "labels = []\n",
    "sents_train = []\n",
    "num = 0\n",
    "with open('train_filter.data', 'r') as infile:\n",
    "    for line in infile:\n",
    "        j=[]\n",
    "        line = line.rstrip().split('\\t')\n",
    "        pairs = chunks(line[2:], 17)\n",
    "\n",
    "        id_ = line[0]\n",
    "\n",
    "        if id_ not in documents:\n",
    "            documents[id_] = []\n",
    "\n",
    "        for sent in line[1].split('|'):\n",
    "            documents[id_] += [sent]\n",
    "        for i in documents[id_]:\n",
    "            j+= i.split(' ')\n",
    "        if id_ not in entities:\n",
    "            entities[id_] = OrderedDict()\n",
    "\n",
    "        if id_ not in relations:\n",
    "            relations[id_] = OrderedDict()\n",
    "\n",
    "        for p in pairs:\n",
    "            # pairs\n",
    "            if (p[5], p[11]) not in relations[id_]:\n",
    "                relations[id_][(p[5], p[11])] = PairInfo(p[0], p[1], p[2], p[3], p[4])\n",
    "            else:\n",
    "                print('duplicates!')\n",
    "            ss = int(p[3].split('-')[0])\n",
    "            se = int(p[3].split('-')[1])-1\n",
    "            os = int(p[4].split('-')[0])\n",
    "            oe = int(p[4].split('-')[1])-1\n",
    "            sen = []\n",
    "            for i_t, token in enumerate(j):\n",
    "                if i_t == ss:\n",
    "                    token = '[E1]'+ token\n",
    "                if i_t == se:\n",
    "                    token = token + '[/E1]'\n",
    "                if i_t == os:\n",
    "                    token = '[E2]' + token\n",
    "                if i_t == oe:\n",
    "                    token = token + '[/E2]'\n",
    "                sen.append(token)\n",
    "            tokens = (' ').join(sen)\n",
    "            #texts.append(tokens)\n",
    "            if p[0]!='1:CID:2':\n",
    "                label=0\n",
    "            else:\n",
    "                label=1  \n",
    "            # entities\n",
    "            num = num + 1\n",
    "            datacow = {'id':num,'token':tokens,'label':label}\n",
    "            sents_train.append(datacow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f44b7c2-7a91-45bb-9486-a825bc55687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "entities = {}\n",
    "relations = {}\n",
    "num_entity = {}\n",
    "texts = []\n",
    "labels = []\n",
    "sents_test = []\n",
    "num = 0\n",
    "with open('test_filter.data', 'r') as infile:\n",
    "    for line in infile:\n",
    "        j=[]\n",
    "        line = line.rstrip().split('\\t')\n",
    "        pairs = chunks(line[2:], 17)\n",
    "\n",
    "        id_ = line[0]\n",
    "\n",
    "        if id_ not in documents:\n",
    "            documents[id_] = []\n",
    "\n",
    "        for sent in line[1].split('|'):\n",
    "            documents[id_] += [sent]\n",
    "        for i in documents[id_]:\n",
    "            j+= i.split(' ')\n",
    "        if id_ not in entities:\n",
    "            entities[id_] = OrderedDict()\n",
    "\n",
    "        if id_ not in relations:\n",
    "            relations[id_] = OrderedDict()\n",
    "\n",
    "        for p in pairs:\n",
    "            # pairs\n",
    "            if (p[5], p[11]) not in relations[id_]:\n",
    "                relations[id_][(p[5], p[11])] = PairInfo(p[0], p[1], p[2], p[3], p[4])\n",
    "            else:\n",
    "                print('duplicates!')\n",
    "            ss = int(p[3].split('-')[0])\n",
    "            se = int(p[3].split('-')[1])-1\n",
    "            os = int(p[4].split('-')[0])\n",
    "            oe = int(p[4].split('-')[1])-1\n",
    "            sen = []\n",
    "            for i_t, token in enumerate(j):\n",
    "                if i_t == ss:\n",
    "                    token = '[E1]'+ token\n",
    "                if i_t == se:\n",
    "                    token = token + '[/E1]'\n",
    "                if i_t == os:\n",
    "                    token = '[E2]' + token\n",
    "                if i_t == oe:\n",
    "                    token = token + '[/E2]'\n",
    "                sen.append(token)\n",
    "            tokens = (' ').join(sen)\n",
    "            #texts.append(tokens)\n",
    "            if p[0]!='1:CID:2':\n",
    "                label=0\n",
    "            else:\n",
    "                label=1  \n",
    "            # entities\n",
    "            num = num + 1\n",
    "            datacow = {'id':num,'token':tokens,'label':label}\n",
    "            sents_test.append(datacow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575bb885-8846-42fb-b3ad-181a8d90795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "entities = {}\n",
    "relations = {}\n",
    "num_entity = {}\n",
    "texts = []\n",
    "labels = []\n",
    "sents_dev = []\n",
    "num = 0\n",
    "with open('dev_filter.data', 'r') as infile:\n",
    "    for line in infile:\n",
    "        j=[]\n",
    "        line = line.rstrip().split('\\t')\n",
    "        pairs = chunks(line[2:], 17)\n",
    "\n",
    "        id_ = line[0]\n",
    "\n",
    "        if id_ not in documents:\n",
    "            documents[id_] = []\n",
    "\n",
    "        for sent in line[1].split('|'):\n",
    "            documents[id_] += [sent]\n",
    "        for i in documents[id_]:\n",
    "            j+= i.split(' ')\n",
    "        if id_ not in entities:\n",
    "            entities[id_] = OrderedDict()\n",
    "\n",
    "        if id_ not in relations:\n",
    "            relations[id_] = OrderedDict()\n",
    "\n",
    "        for p in pairs:\n",
    "            # pairs\n",
    "            if (p[5], p[11]) not in relations[id_]:\n",
    "                relations[id_][(p[5], p[11])] = PairInfo(p[0], p[1], p[2], p[3], p[4])\n",
    "            else:\n",
    "                print('duplicates!')\n",
    "            ss = int(p[3].split('-')[0])\n",
    "            se = int(p[3].split('-')[1])-1\n",
    "            os = int(p[4].split('-')[0])\n",
    "            oe = int(p[4].split('-')[1])-1\n",
    "            sen = []\n",
    "            for i_t, token in enumerate(j):\n",
    "                if i_t == ss:\n",
    "                    token = '[E1]'+ token\n",
    "                if i_t == se:\n",
    "                    token = token + '[/E1]'\n",
    "                if i_t == os:\n",
    "                    token = '[E2]' + token\n",
    "                if i_t == oe:\n",
    "                    token = token + '[/E2]'\n",
    "                sen.append(token)\n",
    "            tokens = (' ').join(sen)\n",
    "            #texts.append(tokens)\n",
    "            if p[0]!='1:CID:2':\n",
    "                label=0\n",
    "            else:\n",
    "                label=1  \n",
    "            # entities\n",
    "            num = num + 1\n",
    "            datacow = {'id':num,'token':tokens,'label':label}\n",
    "            sents_dev.append(datacow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f91c6fac-96ec-4de2-9a43-1cf79c5fc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.data_utils import InputExample\n",
    "dataset = {}\n",
    "for split in ['train']:\n",
    "    dataset[split] = []\n",
    "    for data in sents_train:\n",
    "        input_example = InputExample(text_a = data['token'], label=int(data['label']), guid=data['id'])\n",
    "        dataset[split].append(input_example)\n",
    "for split in ['test']:\n",
    "    dataset[split] = []\n",
    "    for data in sents_test:\n",
    "        input_example = InputExample(text_a = data['token'], label=int(data['label']), guid=data['id'])\n",
    "        dataset[split].append(input_example)\n",
    "for split in ['validation']:\n",
    "    dataset[split] = []\n",
    "    for data in sents_dev:\n",
    "        input_example = InputExample(text_a = data['token'], label=int(data['label']), guid=data['id'])\n",
    "        dataset[split].append(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e067b5ef-34cb-4865-9289-a3ad131d4db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:165: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 1024 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 1024 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 1024 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# You can load the plm related things provided by openprompt simply by calling:\n",
    "from openprompt.plms import load_plm\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"t5\", \"t5-base\")\n",
    "#plm, tokenizer, model_config, WrapperClass = load_plm(\"gpt2\", \"gpt2\")\n",
    "# Constructing Template\n",
    "# A template can be constructed from the yaml config, but it can also be constructed by directly passing arguments.\n",
    "from openprompt.prompts import ManualTemplate\n",
    "\n",
    "template_text1 = '{\"placeholder\":\"text_a\"} {\"mask\"}.'\n",
    "template_text2 = '{\"placeholder\":\"text_a\"} is {\"mask\"}.'\n",
    "template_text3 = '{\"placeholder\":\"text_a\"} The relation is {\"mask\"}.'\n",
    "template_text4 = '{\"placeholder\":\"text_a\"} The relations between entities is {\"mask\"}.'\n",
    "\n",
    "mytemplate = ManualTemplate(tokenizer=tokenizer, text=template_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d374555a-85dd-43bd-a8dc-9daef1aaf40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openprompt.plms import T5TokenizerWrapper\n",
    "from openprompt.plms import T5TokenizerWrapper\n",
    "wrapped_t5tokenizer= T5TokenizerWrapper(max_seq_length=512, decoder_max_length=3, tokenizer=tokenizer,truncate_method=\"head\")\n",
    "\n",
    "# You can see what a tokenized example looks like by \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf966ec6-be35-42d7-8557-70a89dd2db97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "model_inputs = {}\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    model_inputs[split] = []\n",
    "    for sample in dataset[split]:\n",
    "        tokenized_example = wrapped_t5tokenizer.tokenize_one_example(mytemplate.wrap_one_example(sample), teacher_forcing=False)\n",
    "        model_inputs[split].append(tokenized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ec622c3-24ca-4516-b724-29ac1c3a2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 5432it [00:13, 400.13it/s]\n",
      "tokenizing: 5261it [00:12, 413.87it/s]\n",
      "tokenizing: 5405it [00:13, 389.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from openprompt import PromptDataLoader\n",
    "from openprompt.utils.metrics import classification_metrics\n",
    "train_dataloader = PromptDataLoader(dataset=dataset['train'], template=mytemplate, tokenizer=tokenizer, \n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=3, \n",
    "    batch_size=4,shuffle=True, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")\n",
    "validation_dataloader = PromptDataLoader(dataset=dataset[\"validation\"], template=mytemplate, tokenizer=tokenizer, \n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=3, \n",
    "    batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")\n",
    "test_dataloader = PromptDataLoader(dataset=dataset[\"test\"], template=mytemplate, tokenizer=tokenizer, \n",
    "    tokenizer_wrapper_class=WrapperClass, max_seq_length=512, decoder_max_length=3, \n",
    "    batch_size=4,shuffle=False, teacher_forcing=False, predict_eos_token=False,\n",
    "    truncate_method=\"head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f109eb-6e57-4119-9b92-f306e932a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import SoftVerbalizer\n",
    "import torch\n",
    "\n",
    "# for example the verbalizer contains multiple label words in each class\n",
    "# myverbalizer = SoftVerbalizer(tokenizer, plm, num_classes=4,\n",
    "#          label_words=[\"politics\", \"sports\", \"business\", \"technology\"])\n",
    "# or without label words\n",
    "myverbalizer = SoftVerbalizer(tokenizer, plm, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1139899-ad6f-41f1-ac6d-13f26b29c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(2,len(tokenizer)) # creating a pseudo output from the plm, and \n",
    "#print(myverbalizer.process_logits(logits)) # see what the verbalizer do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e0cc38-b4eb-4ed4-a61c-a179b50633f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prompt_model, dataloader, desc):\n",
    "    prompt_model.eval()\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "   \n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        \n",
    "        labels = inputs['label']\n",
    "        alllabels.extend(labels.cpu().tolist())\n",
    "        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "    score = classification_metrics(alllabels, allpreds, \"micro-f1\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a758e3-bce6-48a9-b51d-a5bb902cd166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateprint(prompt_model, dataloader, desc):\n",
    "    prompt_model.eval()\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "   \n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        hidden = prompt_model.prompt_model(inputs)\n",
    "        hidden = prompt_model.verbalizer.gather_outputs(hidden)\n",
    "        outputs_at_mask = prompt_model.extract_at_mask(hidden, inputs)\n",
    "        labels = inputs['label']\n",
    "        alllabels.extend(labels.cpu().tolist())\n",
    "        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "    score = classification_metrics(alllabels, allpreds, \"micro-f1\")\n",
    "    return alllabels,allpreds,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07872da9-9c08-44d3-92b0-03ad3471e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatetest(prompt_model, dataloader, desc):\n",
    "    prompt_model.eval()\n",
    "    allpreds = []\n",
    "    alllabels = []\n",
    "   \n",
    "    for step, inputs in enumerate(dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        alllabels.extend(labels.cpu().tolist())\n",
    "        allpreds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "    score = classification_metrics(alllabels, allpreds, \"micro-f1\")\n",
    "    return alllabels,allpreds,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e21f07-d98a-432e-8a01-10ae6613e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Although you can manually combine the plm, template, verbalizer together, we provide a pipeline \n",
    "# model which take the batched data from the PromptDataLoader and produce a class-wise logits\n",
    "\n",
    "from openprompt import PromptForClassification\n",
    "\n",
    "use_cuda = True\n",
    "prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n",
    "if use_cuda:\n",
    "    prompt_model=  prompt_model.cuda()\n",
    "\n",
    "# Now the training is standard\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf96c61f-52c1-44f2-8ecb-5cc64a15c167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, average loss: 0.713019847869873\n",
      "Epoch 0, average loss: 0.49183981955616535\n",
      "Epoch 0, val_acc: 0.8076411328644745\n",
      "Epoch 1, average loss: 0.19491544365882874\n",
      "Epoch 1, average loss: 0.45896347315085984\n",
      "Epoch 1, val_acc: 0.8082113666603308\n",
      "Epoch 2, average loss: 0.6699537932872772\n",
      "Epoch 2, average loss: 0.3754803715571166\n",
      "Epoch 2, val_acc: 0.778369131343851\n",
      "Epoch 3, average loss: 0.20336908102035522\n",
      "Epoch 3, average loss: 0.3093956710980785\n",
      "Epoch 3, val_acc: 0.8378635240448584\n",
      "Epoch 4, average loss: 0.13924746587872505\n",
      "Epoch 4, average loss: 0.24219476047367927\n",
      "Epoch 4, val_acc: 0.8490781220300323\n",
      "Epoch 5, average loss: 0.21952487528324127\n",
      "Epoch 5, average loss: 0.17710736055510815\n",
      "Epoch 5, val_acc: 0.8093518342520434\n",
      "Epoch 6, average loss: 0.07024658843874931\n",
      "Epoch 6, average loss: 0.15264000511133835\n",
      "Epoch 6, val_acc: 0.8327314198821516\n",
      "Epoch 7, average loss: 0.019758321810513735\n",
      "Epoch 7, average loss: 0.11675445420749786\n",
      "Epoch 7, val_acc: 0.8296901729709181\n",
      "Epoch 8, average loss: 0.11505222506821156\n",
      "Epoch 8, average loss: 0.09994267941057657\n",
      "Epoch 8, val_acc: 0.8336818095419122\n",
      "Epoch 9, average loss: 0.05500466749072075\n",
      "Epoch 9, average loss: 0.06901733476808364\n",
      "Epoch 9, val_acc: 0.8467971868466071\n"
     ]
    }
   ],
   "source": [
    "# Although you can manually combine the plm, template, verbalizer together, we provide a pipeline \n",
    "# model which take the batched data from the PromptDataLoader and produce a class-wise logits\n",
    "\n",
    "from openprompt import PromptForClassification\n",
    "\n",
    "use_cuda = True\n",
    "prompt_model = PromptForClassification(plm=plm,template=mytemplate, verbalizer=myverbalizer, freeze_plm=False)\n",
    "if use_cuda:\n",
    "    prompt_model=  prompt_model.cuda()\n",
    "\n",
    "# Now the training is standard\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-4)\n",
    "\n",
    "\n",
    "best_val_f1 = 0\n",
    "\n",
    "leave_training = False\n",
    "\n",
    "f1_traces = []\n",
    "\n",
    "prompt_model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "    tot_loss = 0 \n",
    "    for step, inputs in enumerate(train_dataloader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        logits = prompt_model(inputs)\n",
    "        labels = inputs['label']\n",
    "        loss = loss_func(logits, labels)\n",
    "        loss.backward()\n",
    "        tot_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step %1000 ==1:\n",
    "            print(\"Epoch {}, average loss: {}\".format(epoch, tot_loss/(step+1)), flush=True)\n",
    "    val_f1 = evaluate(prompt_model, validation_dataloader, desc=\"Valid\")\n",
    "    print(\"Epoch {}, val_acc: {}\".format(epoch, val_f1), flush=True)\n",
    "    if epoch > 0:\n",
    "        \n",
    "        if val_f1 >= best_val_f1:\n",
    "            torch.save(prompt_model.state_dict(),f\"tempalte1.ckpt\")\n",
    "            best_val_f1 = val_f1\n",
    "            \n",
    "        f1_traces.append(val_f1)\n",
    "            #print(\"Glb_step {}, val_acc {}, average time {}\".format(glb_step, val_acc, tot_train_time/actual_step ), flush=True)\n",
    "    prompt_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a123896-5ecb-4c72-adf0-5cb9803e4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_model.load_state_dict(torch.load(f\"tempalte1.ckpt\"))\n",
    "prompt_model = prompt_model.cuda()\n",
    "a,b,test_f1 = evaluatetest(prompt_model, test_dataloader, desc=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be40a116-6274-40bc-98c6-a0be2e188124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, f1_score, precision_recall_fscore_support\n",
    "p,r,f,s = precision_recall_fscore_support(y_pred=a, y_true=b, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba38fbb9-e064-4f9f-9d35-8e3c5b0e079d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814722441904157"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b38794-5315-4604-ac15-c95e50adf46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7730290399744464"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdf87a3f-c735-47ca-aa50-060788cad282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709896957942898"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79cce84-6df0-4f18-b143-fdb3e350f6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
